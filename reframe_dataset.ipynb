{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reframe dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this process I will select a specific pollutant to forecast along with exegenous variables that can influence its values, and reframe the current information as a supervised learning dataset. This step is necessary so that the LTSM can be correctly trained with the data it's given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriagonzalez/Documents/aqi/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna # Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"semadet-aire-final\"\n",
    "filepath = f\"datasets/feature_eng/{filename}.csv\"\n",
    "df = pd.read_csv(filepath, parse_dates=[0], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select pollutant to predict and exegenous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset to reframe will contain PM2.5 as the independent variable and temperature, relative humidity, wind speed and wind direction as the dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"pm25\", \"tmp\", \"rh\", \"ws\", \"wd\"]\n",
    "pollutant = \"pm25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_df_features(df:pd.DataFrame, features:list):\n",
    "    df_select = pd.DataFrame()\n",
    "    for feature in features:\n",
    "        df_select[feature] = df[feature]\n",
    "    return df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = select_df_features(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>tmp</th>\n",
       "      <th>rh</th>\n",
       "      <th>ws</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>24.869231</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>52.125000</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>9.648721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>24.869231</td>\n",
       "      <td>19.358333</td>\n",
       "      <td>49.691667</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>9.957045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>24.869231</td>\n",
       "      <td>19.970833</td>\n",
       "      <td>43.037500</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>11.695896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pm25        tmp         rh        ws         wd\n",
       "date                                                            \n",
       "2017-01-01  24.869231  19.475000  52.125000  2.516667   9.648721\n",
       "2017-01-02  24.869231  19.358333  49.691667  1.291667   9.957045\n",
       "2017-01-03  24.869231  19.970833  43.037500  1.062500  11.695896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is separated, it's important to normalize all the values. The data will be transformed to a common scale to improve the model's performance. In this case, the data held for each feature will be scaled to have values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data_norm = data_scaler.fit_transform(df_select.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22140047, 0.43233533, 0.54997636, 0.43192939, 0.02718241],\n",
       "       [0.22140047, 0.42517661, 0.51689848, 0.21843369, 0.02805866],\n",
       "       [0.22140047, 0.46275987, 0.42644408, 0.17849402, 0.03300044],\n",
       "       [0.22140047, 0.50264415, 0.36096801, 0.20173165, 0.03609954],\n",
       "       [0.22140047, 0.57934468, 0.26972064, 0.40723941, 0.04108343]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries to supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, column_names, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [(f\"{column_names[j]}(t-{i})\") for j in range(n_vars)]\n",
    "    \n",
    "    # Forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(f\"{column_names[j]}(t)\") for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(f\"{column_names[j]}(t+{i})\") for j in range(n_vars)]\n",
    "    \n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reframed = series_to_supervised(data_norm, features, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't want to predict (i.e, drop all features that aren't pm25 for time t)\n",
    "data_reframed.drop(data_reframed.columns[[6,7,8,9]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25(t-1)</th>\n",
       "      <th>tmp(t-1)</th>\n",
       "      <th>rh(t-1)</th>\n",
       "      <th>ws(t-1)</th>\n",
       "      <th>wd(t-1)</th>\n",
       "      <th>pm25(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.432335</td>\n",
       "      <td>0.549976</td>\n",
       "      <td>0.431929</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.425177</td>\n",
       "      <td>0.516898</td>\n",
       "      <td>0.218434</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.462760</td>\n",
       "      <td>0.426444</td>\n",
       "      <td>0.178494</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25(t-1)  tmp(t-1)   rh(t-1)   ws(t-1)   wd(t-1)  pm25(t)\n",
       "1     0.2214  0.432335  0.549976  0.431929  0.027182   0.2214\n",
       "2     0.2214  0.425177  0.516898  0.218434  0.028059   0.2214\n",
       "3     0.2214  0.462760  0.426444  0.178494  0.033000   0.2214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reframed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_series(df: pd.DataFrame, train:float=0.65, val:float=0.15):\n",
    "    data_len = len(df)\n",
    "    train_size = int(data_len * train)\n",
    "    val_size = int(data_len * val)\n",
    "    \n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        train_df[feature] = df[feature][:train_size]\n",
    "        val_df[feature] = df[feature][train_size:train_size + val_size]\n",
    "        test_df[feature] = df[feature][train_size + val_size:]\n",
    "    \n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = divide_series(data_reframed, train=0.56, val=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set len: 613\n",
      "Validation set len: 109\n",
      "Test set len: 373\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set len: {len(train_df)}\")\n",
    "print(f\"Validation set len: {len(val_df)}\")\n",
    "print(f\"Test set len: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25(t-1)</th>\n",
       "      <th>tmp(t-1)</th>\n",
       "      <th>rh(t-1)</th>\n",
       "      <th>ws(t-1)</th>\n",
       "      <th>wd(t-1)</th>\n",
       "      <th>pm25(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.432335</td>\n",
       "      <td>0.549976</td>\n",
       "      <td>0.431929</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.425177</td>\n",
       "      <td>0.516898</td>\n",
       "      <td>0.218434</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.462760</td>\n",
       "      <td>0.426444</td>\n",
       "      <td>0.178494</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25(t-1)  tmp(t-1)   rh(t-1)   ws(t-1)   wd(t-1)  pm25(t)\n",
       "1     0.2214  0.432335  0.549976  0.431929  0.027182   0.2214\n",
       "2     0.2214  0.425177  0.516898  0.218434  0.028059   0.2214\n",
       "3     0.2214  0.462760  0.426444  0.178494  0.033000   0.2214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(f\"datasets/reframe/train_{pollutant}.csv\", index=False)\n",
    "# val_df.to_csv(f\"datasets/reframe/val_{pollutant}.csv\", index=False)\n",
    "# test_df.to_csv(f\"datasets/reframe/test_{pollutant}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Split the data into inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613, 6)\n"
     ]
    }
   ],
   "source": [
    "train_values = train_df.values\n",
    "val_values = val_df.values\n",
    "test_values = test_df.values\n",
    "print(train_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_values[:,:-1], train_values[:,-1]\n",
    "val_X, val_y = val_values[:,:-1], val_values[:,-1]\n",
    "test_X, test_y = test_values[:,:-1], test_values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the input to be 3d format [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3065 into shape (613,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_X \u001b[38;5;241m=\u001b[39m val_X\u001b[38;5;241m.\u001b[39mreshape(val_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, val_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m test_X \u001b[38;5;241m=\u001b[39m test_X\u001b[38;5;241m.\u001b[39mreshape(test_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, test_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3065 into shape (613,1,1)"
     ]
    }
   ],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "test_X = test_X.reshape(test_X.shape[0], 1, test_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape(test_X.shape[0], 1, test_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613, 1, 5) (109, 1, 5) (373, 1, 5)\n",
      "(613,) (109,) (373,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, val_X.shape, test_X.shape)\n",
    "print(train_y.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.reshape(test_y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and fit ltsm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPOptimizer:\n",
    "  \"\"\"\n",
    "  Class for hyperparameter optimizing for PM2.5 Forecaster.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_dim:int, n_trials:int):\n",
    "    self.input_dim = input_dim\n",
    "    self.n_trials = n_trials\n",
    "    self.study = None\n",
    "    self.X_train = None\n",
    "    self.y_train = None\n",
    "    self.X_val = None\n",
    "    self.y_val = None\n",
    "\n",
    "  def create_model(self, trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hyperparameter selection\n",
    "    neurons = trial.suggest_categorical(\"neurons\", [5, 50])\n",
    "    # dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.2, log=True)\n",
    "    \n",
    "    model.add(LSTM(neurons, \n",
    "                   input_shape=(self.X_train.shape[1], self.X_train.shape[2]),\n",
    "                   activation=\"relu\"))\n",
    "\n",
    "\n",
    "    # Dropout layer\n",
    "    # model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    # learning_rate = trial.suggest_cat(\"learning_rate\", 0.001, 0., log=True)\n",
    "    learning_rate = 0.001\n",
    "    model.compile(optimizer=Adam(learning_rate), loss=\"mse\")\n",
    "\n",
    "    return model\n",
    "\n",
    "  def objective(self, trial):\n",
    "    model = self.create_model(trial)\n",
    "    epochs = trial.suggest_categorical(\"epochs\", [50, 100])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        epochs=epochs,\n",
    "        validation_data=(self.X_val, self.y_val),\n",
    "        verbose=0\n",
    "        )\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    loss = model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def optimize(self, X_train:np.array, y_train:np.array, X_val, y_val:np.array):\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    self.X_val = X_val\n",
    "    self.y_val = y_val\n",
    "\n",
    "    self.study = optuna.create_study(direction=\"minimize\")\n",
    "    self.study.optimize(self.objective, n_trials = self.n_trials)\n",
    "\n",
    "    print(\"Best hyperparameters:\", self.study.best_params)\n",
    "    return self.study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:49:11,011] A new study created in memory with name: no-name-5f687950-080e-4171-9fe9-557d30299ac8\n",
      "/Users/valeriagonzalez/Documents/aqi/env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-04-03 19:49:14,461] Trial 0 finished with value: 0.0044375634752213955 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:16,466] Trial 1 finished with value: 0.004448600113391876 and parameters: {'neurons': 50, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:18,500] Trial 2 finished with value: 0.005482207052409649 and parameters: {'neurons': 5, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:22,292] Trial 3 finished with value: 0.004536195192486048 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:24,381] Trial 4 finished with value: 0.004761840216815472 and parameters: {'neurons': 50, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:28,020] Trial 5 finished with value: 0.005239029880613089 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:31,525] Trial 6 finished with value: 0.004797103814780712 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:33,551] Trial 7 finished with value: 0.0054930695332586765 and parameters: {'neurons': 5, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:35,561] Trial 8 finished with value: 0.005547247361391783 and parameters: {'neurons': 50, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:39,104] Trial 9 finished with value: 0.004485673271119595 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:43,047] Trial 10 finished with value: 0.004551193676888943 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:45,135] Trial 11 finished with value: 0.004608307499438524 and parameters: {'neurons': 50, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:47,119] Trial 12 finished with value: 0.004497119691222906 and parameters: {'neurons': 5, 'epochs': 50}. Best is trial 0 with value: 0.0044375634752213955.\n",
      "[I 2025-04-03 19:49:50,871] Trial 13 finished with value: 0.004432501271367073 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:49:54,439] Trial 14 finished with value: 0.007419409696012735 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:49:58,587] Trial 15 finished with value: 0.0048510609194636345 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:02,232] Trial 16 finished with value: 0.0045714727602899075 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:06,144] Trial 17 finished with value: 0.004945914726704359 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:09,820] Trial 18 finished with value: 0.00460304319858551 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:13,437] Trial 19 finished with value: 0.004728840198367834 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:17,027] Trial 20 finished with value: 0.004447268322110176 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:20,676] Trial 21 finished with value: 0.0054939258843660355 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:24,256] Trial 22 finished with value: 0.007386759389191866 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:27,859] Trial 23 finished with value: 0.005054904147982597 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:31,405] Trial 24 finished with value: 0.004623625427484512 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:34,985] Trial 25 finished with value: 0.004686076659709215 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:39,083] Trial 26 finished with value: 0.004570767283439636 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:42,694] Trial 27 finished with value: 0.00477635907009244 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:46,414] Trial 28 finished with value: 0.004469649866223335 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:50,129] Trial 29 finished with value: 0.004468253813683987 and parameters: {'neurons': 50, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:53,745] Trial 30 finished with value: 0.004776469431817532 and parameters: {'neurons': 5, 'epochs': 100}. Best is trial 13 with value: 0.004432501271367073.\n",
      "[I 2025-04-03 19:50:55,818] Trial 31 finished with value: 0.005342870019376278 and parameters: {'neurons': 50, 'epochs': 50}. Best is trial 13 with value: 0.004432501271367073.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'neurons': 50, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "mlp_optimizer = MLPOptimizer(n_steps, 32)\n",
    "study = mlp_optimizer.optimize(train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer in the network must define the number of inputs to expect. Input must be three-dimensional, comprised of samples, timesteps, and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriagonzalez/Documents/aqi/env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, \n",
    "               input_shape=(train_X.shape[1], train_X.shape[2]),\n",
    "               activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer=Adam(0.001))\n",
    "# fit network\n",
    "history = model.fit(\n",
    "    train_X, \n",
    "    train_y, \n",
    "    epochs=100, \n",
    "    batch_size=72, \n",
    "    validation_data=(val_X, val_y),\n",
    "    verbose=0, \n",
    "    shuffle=False\n",
    "    )\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 12.003\n"
     ]
    }
   ],
   "source": [
    "# invert scaling for forecast\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = data_scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = data_scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 33.54545454545455  Predict: 28.42788571678102\n",
      "Actual: 33.54545454545455  Predict: 28.876362567022444\n",
      "Actual: 33.54545454545455  Predict: 30.476809175685048\n",
      "Actual: 33.54545454545455  Predict: 28.384192102029917\n",
      "Actual: 33.54545454545455  Predict: 29.33955514729023\n",
      "Actual: 33.54545454545455  Predict: 29.931567971780897\n",
      "Actual: 33.54545454545455  Predict: 28.828732306510208\n",
      "Actual: 33.54545454545455  Predict: 28.422316684946416\n",
      "Actual: 18.194166666666668  Predict: 28.018678302690386\n",
      "Actual: 18.194166666666668  Predict: 18.84549689050764\n",
      "Actual: 24.24833333333333  Predict: 18.403485307842494\n",
      "Actual: 42.72625  Predict: 22.395782578736544\n",
      "Actual: 66.06416666666667  Predict: 34.81573986969888\n",
      "Actual: 53.97125  Predict: 52.01404290050267\n",
      "Actual: 55.071250000000006  Predict: 43.61932651735842\n",
      "Actual: 47.17625  Predict: 43.21614413596689\n",
      "Actual: 50.98  Predict: 37.38232860788703\n",
      "Actual: 60.373333333333335  Predict: 40.62854054942727\n",
      "Actual: 62.60583333333333  Predict: 47.54869324341416\n",
      "Actual: 50.78958333333333  Predict: 48.02973534688353\n",
      "Actual: 72.98333333333333  Predict: 40.81007497869432\n",
      "Actual: 61.88916666666666  Predict: 59.390356544405215\n",
      "Actual: 40.315  Predict: 49.96141322180628\n",
      "Actual: 46.190000000000005  Predict: 32.35987444780767\n",
      "Actual: 66.49458333333334  Predict: 36.649996070563795\n",
      "Actual: 58.45625  Predict: 50.97390977963805\n",
      "Actual: 72.15791666666667  Predict: 45.077874388918275\n",
      "Actual: 65.83291666666666  Predict: 55.15175089165568\n",
      "Actual: 43.470416666666665  Predict: 50.10493706837296\n",
      "Actual: 41.925  Predict: 34.3228659991175\n",
      "Actual: 66.53458333333333  Predict: 34.10188264399767\n",
      "Actual: 33.2025  Predict: 52.42583593651652\n",
      "Actual: 47.37166666666667  Predict: 27.82141184359789\n",
      "Actual: 60.22541666666667  Predict: 37.74565942436457\n",
      "Actual: 45.920416666666654  Predict: 47.61503651812672\n",
      "Actual: 34.87708333333333  Predict: 36.94375764876604\n",
      "Actual: 22.161739130434785  Predict: 28.700930787622926\n",
      "Actual: 31.56136363636364  Predict: 21.2541383292526\n",
      "Actual: 44.88291666666667  Predict: 27.06515623964369\n",
      "Actual: 45.374583333333334  Predict: 35.76729967370629\n",
      "Actual: 34.55125  Predict: 36.64323367476463\n",
      "Actual: 63.89791666666667  Predict: 28.661118031293153\n",
      "Actual: 54.08083333333333  Predict: 53.293591028451914\n",
      "Actual: 68.27333333333333  Predict: 45.14646613597869\n",
      "Actual: 50.18625  Predict: 53.04433804526924\n",
      "Actual: 49.1325  Predict: 40.07486575506628\n",
      "Actual: 44.48083333333333  Predict: 38.44679228551686\n",
      "Actual: 43.82333333333333  Predict: 35.32986144013703\n",
      "Actual: 57.63583333333333  Predict: 34.80194826908409\n",
      "Actual: 63.15708333333333  Predict: 44.449075877666466\n",
      "Actual: 45.91333333333334  Predict: 52.52803834304213\n",
      "Actual: 41.74619047619048  Predict: 37.06102748811245\n",
      "Actual: 44.024166666666666  Predict: 33.09894512556493\n",
      "Actual: 43.04791666666668  Predict: 35.33647102713585\n",
      "Actual: 36.94875  Predict: 34.171252988278866\n",
      "Actual: 57.61708333333333  Predict: 30.171383192390202\n",
      "Actual: 66.44375000000001  Predict: 45.71628772690892\n",
      "Actual: 39.865833333333335  Predict: 52.5810072094202\n",
      "Actual: 46.794545454545464  Predict: 32.14300480261445\n",
      "Actual: 38.2825  Predict: 36.87902978137136\n",
      "Actual: 34.415  Predict: 30.75796766616404\n",
      "Actual: 60.52666666666667  Predict: 28.35616745315492\n",
      "Actual: 60.52666666666667  Predict: 45.771871321648355\n",
      "Actual: 37.08708333333333  Predict: 47.566918724775306\n",
      "Actual: 38.9625  Predict: 30.111659206822512\n",
      "Actual: 41.06375  Predict: 32.022203382104635\n",
      "Actual: 51.739583333333336  Predict: 33.158196131512526\n",
      "Actual: 43.79833333333333  Predict: 40.935953047126524\n",
      "Actual: 38.90958333333334  Predict: 34.55199430584908\n",
      "Actual: 42.550000000000004  Predict: 30.69821457415819\n",
      "Actual: 44.17166666666665  Predict: 33.86908935159445\n",
      "Actual: 45.03916666666667  Predict: 34.98429040201008\n",
      "Actual: 55.53958333333333  Predict: 35.90241661071777\n",
      "Actual: 56.69625  Predict: 42.601784843578926\n",
      "Actual: 59.76458333333333  Predict: 43.259425409510726\n",
      "Actual: 55.304782608695646  Predict: 45.64740976653992\n",
      "Actual: 68.100625  Predict: 42.894316674768916\n",
      "Actual: 55.07  Predict: 52.3117484010756\n",
      "Actual: 37.61666666666667  Predict: 42.22000054530799\n",
      "Actual: 47.068260869565215  Predict: 30.5390193361789\n",
      "Actual: 30.57625  Predict: 36.689816103503105\n",
      "Actual: 60.69391304347826  Predict: 25.84398835003376\n",
      "Actual: 53.39136363636363  Predict: 47.96701097264885\n",
      "Actual: 45.25333333333333  Predict: 41.443324349448076\n",
      "Actual: 41.18125  Predict: 35.1150098413229\n",
      "Actual: 25.082083333333333  Predict: 32.194190899655226\n",
      "Actual: 28.080416666666665  Predict: 23.2048506019637\n",
      "Actual: 29.19125  Predict: 24.69527244884521\n",
      "Actual: 65.4305  Predict: 25.28009113203734\n",
      "Actual: 43.51791666666667  Predict: 50.81959229558706\n",
      "Actual: 49.64952380952381  Predict: 33.65569550022483\n",
      "Actual: 54.72272727272728  Predict: 38.03290601149202\n",
      "Actual: 46.92083333333333  Predict: 42.4951024711132\n",
      "Actual: 67.76125  Predict: 36.335205090790986\n",
      "Actual: 86.4604761904762  Predict: 50.811597727239125\n",
      "Actual: 75.45  Predict: 64.76810571849346\n",
      "Actual: 76.72  Predict: 57.84577004164457\n",
      "Actual: 57.04208333333334  Predict: 57.49989338591694\n",
      "Actual: 64.61090909090909  Predict: 43.25601025409996\n",
      "Actual: 49.51285714285714  Predict: 48.733189446479074\n",
      "Actual: 64.33869565217391  Predict: 38.13530003540218\n",
      "Actual: 50.47916666666667  Predict: 48.71040395647287\n",
      "Actual: 51.114999999999995  Predict: 38.60873323082924\n",
      "Actual: 50.1752380952381  Predict: 39.43370185866952\n",
      "Actual: 46.17416666666667  Predict: 38.7902337025851\n",
      "Actual: 37.4404347826087  Predict: 36.20245790295303\n",
      "Actual: 31.527619047619048  Predict: 30.108818903565407\n",
      "Actual: 51.43  Predict: 26.69376051425934\n",
      "Actual: 46.48739130434783  Predict: 39.2007994171232\n",
      "Actual: 47.80583333333333  Predict: 36.372080522403124\n",
      "Actual: 54.592499999999994  Predict: 37.0929014634341\n",
      "Actual: 53.06250000000001  Predict: 41.86377169974148\n",
      "Actual: 35.081250000000004  Predict: 40.892514113709325\n",
      "Actual: 36.593125  Predict: 28.313388265669346\n",
      "Actual: 52.373043478260875  Predict: 29.871062963455916\n",
      "Actual: 34.568333333333335  Predict: 40.54308404698968\n",
      "Actual: 37.662608695652175  Predict: 27.97615379653871\n",
      "Actual: 58.314499999999995  Predict: 29.99518736898899\n",
      "Actual: 52.2755  Predict: 43.73660605885088\n",
      "Actual: 53.4252380952381  Predict: 38.99359310939908\n",
      "Actual: 37.165238095238095  Predict: 40.760302969440815\n",
      "Actual: 44.17227272727273  Predict: 29.768292981386185\n",
      "Actual: 58.48090909090908  Predict: 33.866062282025815\n",
      "Actual: 42.95  Predict: 44.21802654601633\n",
      "Actual: 60.24095238095238  Predict: 33.31582204736769\n",
      "Actual: 53.19608695652174  Predict: 45.111737304180856\n",
      "Actual: 49.64368421052631  Predict: 40.22365301586687\n",
      "Actual: 67.5604347826087  Predict: 38.83494119159877\n",
      "Actual: 54.55782608695652  Predict: 51.87742698192596\n",
      "Actual: 62.51363636363636  Predict: 41.92355389818549\n",
      "Actual: 77.9825  Predict: 47.49334735125303\n",
      "Actual: 77.9825  Predict: 58.47841302827\n",
      "Actual: 74.02666666666667  Predict: 58.83587889745831\n",
      "Actual: 62.636818181818185  Predict: 55.22445392310619\n",
      "Actual: 44.14904761904762  Predict: 47.04825169891119\n",
      "Actual: 52.37125  Predict: 33.92113408856094\n",
      "Actual: 53.44294117647058  Predict: 39.58295482248068\n",
      "Actual: 55.650454545454544  Predict: 40.160264044627546\n",
      "Actual: 45.47533333333333  Predict: 41.719733639433976\n",
      "Actual: 55.11615384615384  Predict: 34.87207052968442\n",
      "Actual: 60.03578947368421  Predict: 41.951314163580534\n",
      "Actual: 58.64238095238095  Predict: 45.44615815095603\n",
      "Actual: 50.376086956521746  Predict: 44.73232760615646\n",
      "Actual: 56.36954545454545  Predict: 38.64311035983265\n",
      "Actual: 40.9  Predict: 43.441745712608096\n",
      "Actual: 43.083333333333336  Predict: 32.11106533780694\n",
      "Actual: 69.13416666666667  Predict: 33.45803367868066\n",
      "Actual: 32.67333333333333  Predict: 52.78679457828402\n",
      "Actual: 25.829565217391306  Predict: 29.53846126906574\n",
      "Actual: 47.25521739130435  Predict: 24.212969066388904\n",
      "Actual: 46.2205  Predict: 36.91919666603208\n",
      "Actual: 53.40842105263158  Predict: 35.7545437771827\n",
      "Actual: 46.23086956521739  Predict: 40.43286524228751\n",
      "Actual: 54.7321052631579  Predict: 35.9312101546675\n",
      "Actual: 45.875789473684215  Predict: 42.384000771120185\n",
      "Actual: 45.43166666666666  Predict: 36.05297936424613\n",
      "Actual: 39.90130434782609  Predict: 34.78010146170855\n",
      "Actual: 34.41888888888889  Predict: 31.029770862311125\n",
      "Actual: 52.3552380952381  Predict: 28.189079519361258\n",
      "Actual: 45.68809523809525  Predict: 40.26374470889568\n",
      "Actual: 47.812105263157896  Predict: 35.13084859475494\n",
      "Actual: 40.778823529411774  Predict: 36.975869326666\n",
      "Actual: 38.43714285714285  Predict: 31.910281850770115\n",
      "Actual: 31.443  Predict: 30.538643378019334\n",
      "Actual: 50.864285714285714  Predict: 26.53049522601068\n",
      "Actual: 43.17318181818182  Predict: 39.4982841938734\n",
      "Actual: 46.38652173913044  Predict: 33.41500708647072\n",
      "Actual: 42.34238095238096  Predict: 35.36272745989263\n",
      "Actual: 51.86  Predict: 33.82066594064236\n",
      "Actual: 37.912  Predict: 40.116696557775136\n",
      "Actual: 41.9975  Predict: 30.52665637657046\n",
      "Actual: 51.142222222222216  Predict: 32.75636962503195\n",
      "Actual: 55.121111111111105  Predict: 41.247685425356025\n",
      "Actual: 51.34736842105264  Predict: 42.87862345352768\n",
      "Actual: 51.61  Predict: 39.83864275403321\n",
      "Actual: 58.73449999999999  Predict: 39.63018972054124\n",
      "Actual: 58.13857142857143  Predict: 45.58812965415417\n",
      "Actual: 51.038947368421056  Predict: 45.39589375779032\n",
      "Actual: 58.98842105263159  Predict: 39.67301499322057\n",
      "Actual: 64.67190476190477  Predict: 46.065773580968376\n",
      "Actual: 64.67190476190477  Predict: 50.51861232072115\n",
      "Actual: 60.191999999999986  Predict: 49.97267741337418\n",
      "Actual: 60.48541666666667  Predict: 47.90206480696797\n",
      "Actual: 35.31227272727273  Predict: 48.11085499003529\n",
      "Actual: 37.36833333333333  Predict: 29.64332448914647\n",
      "Actual: 32.40347826086956  Predict: 32.10041723251343\n",
      "Actual: 28.005714285714287  Predict: 26.8066910687834\n",
      "Actual: 41.50565217391304  Predict: 24.029616697505116\n",
      "Actual: 21.024166666666662  Predict: 32.31663925945759\n",
      "Actual: 13.144210526315788  Predict: 19.941885479725897\n",
      "Actual: 13.555652173913042  Predict: 14.515894809924067\n",
      "Actual: 24.612608695652174  Predict: 15.36430139709264\n",
      "Actual: 26.84913043478261  Predict: 22.219477606192232\n",
      "Actual: 23.8275  Predict: 25.096982529573143\n",
      "Actual: 31.453043478260867  Predict: 23.089999022521077\n",
      "Actual: 29.355217391304347  Predict: 28.19847362227738\n",
      "Actual: 19.005789473684214  Predict: 26.778711292333902\n",
      "Actual: 14.912727272727272  Predict: 21.738793269358574\n",
      "Actual: 22.63904761904762  Predict: 18.966853758879004\n",
      "Actual: 19.7375  Predict: 24.226696390286087\n",
      "Actual: 16.440555555555555  Predict: 22.237040916085242\n",
      "Actual: 24.91130434782609  Predict: 20.002185530215502\n",
      "Actual: 34.054545454545455  Predict: 25.800342033244668\n",
      "Actual: 27.799  Predict: 32.270668065920475\n",
      "Actual: 29.916249999999998  Predict: 27.819908010959626\n",
      "Actual: 41.91652173913044  Predict: 29.314683695882557\n",
      "Actual: 27.94772727272727  Predict: 38.01203184425831\n",
      "Actual: 26.74681818181818  Predict: 27.92451897524297\n",
      "Actual: 36.0565  Predict: 27.081487376987933\n",
      "Actual: 28.758750000000003  Predict: 33.71700578667223\n",
      "Actual: 20.355454545454545  Predict: 27.06510166507214\n",
      "Actual: 19.163000000000004  Predict: 20.895077669806778\n",
      "Actual: 16.851363636363637  Predict: 21.06012694016099\n",
      "Actual: 19.635  Predict: 18.670316154137254\n",
      "Actual: 19.039444444444445  Predict: 18.85952619370073\n",
      "Actual: 22.777391304347827  Predict: 18.440851910598575\n",
      "Actual: 28.256190476190476  Predict: 20.789192086085677\n",
      "Actual: 24.873043478260872  Predict: 23.811297794245185\n",
      "Actual: 12.08  Predict: 21.891352239437403\n",
      "Actual: 14.462105263157891  Predict: 14.15456688022241\n",
      "Actual: 20.045882352941177  Predict: 14.75486776297912\n",
      "Actual: 23.752608695652167  Predict: 18.655817509628832\n",
      "Actual: 23.325333333333333  Predict: 20.955776721052825\n",
      "Actual: 18.912500000000005  Predict: 20.69844063743949\n",
      "Actual: 19.347368421052636  Predict: 18.951601985283197\n",
      "Actual: 17.9945  Predict: 19.291115245968104\n",
      "Actual: 16.4865  Predict: 18.7391674336046\n",
      "Actual: 19.142  Predict: 17.29649348575622\n",
      "Actual: 20.181428571428572  Predict: 22.837614671699704\n",
      "Actual: 21.92  Predict: 19.308814385905862\n",
      "Actual: 24.003636363636364  Predict: 20.654408660344778\n",
      "Actual: 24.537  Predict: 21.497086130268872\n",
      "Actual: 17.421428571428574  Predict: 21.574153914675115\n",
      "Actual: 23.385  Predict: 17.857100463472307\n",
      "Actual: 24.558695652173913  Predict: 20.702629538998007\n",
      "Actual: 23.10772727272727  Predict: 21.100241675786673\n",
      "Actual: 18.98952380952381  Predict: 20.104166000150144\n",
      "Actual: 17.29  Predict: 18.035448950529098\n",
      "Actual: 12.232173913043477  Predict: 17.704935643076897\n",
      "Actual: 14.687142857142856  Predict: 15.429579861275851\n",
      "Actual: 25.761666666666667  Predict: 16.361392766144128\n",
      "Actual: 30.648749999999996  Predict: 22.157305041514338\n",
      "Actual: 24.919583333333335  Predict: 25.274377780780195\n",
      "Actual: 17.006666666666664  Predict: 21.503211822733284\n",
      "Actual: 22.142727272727267  Predict: 17.840478261746465\n",
      "Actual: 16.42304347826087  Predict: 19.947990555129945\n",
      "Actual: 23.58458333333333  Predict: 17.036335290409625\n",
      "Actual: 18.496470588235297  Predict: 21.265256988629698\n",
      "Actual: 22.902916666666663  Predict: 18.39529912211001\n",
      "Actual: 27.406666666666666  Predict: 20.976766101270915\n",
      "Actual: 17.13375  Predict: 23.679289182275532\n",
      "Actual: 22.22347826086957  Predict: 17.77552118115127\n",
      "Actual: 23.37227272727273  Predict: 20.581717756576836\n",
      "Actual: 25.409999999999997  Predict: 21.223283079266547\n",
      "Actual: 23.069  Predict: 22.42918949313462\n",
      "Actual: 26.141739130434782  Predict: 21.005458985455334\n",
      "Actual: 21.992777777777782  Predict: 22.82784339785576\n",
      "Actual: 19.25714285714286  Predict: 20.520288618840276\n",
      "Actual: 22.126521739130432  Predict: 18.927606152556837\n",
      "Actual: 24.7585  Predict: 20.576253022812306\n",
      "Actual: 22.599444444444444  Predict: 22.09544537104666\n",
      "Actual: 26.10909090909091  Predict: 20.20552310720086\n",
      "Actual: 26.405833333333337  Predict: 22.80538171697408\n",
      "Actual: 22.35636363636364  Predict: 22.833559174649416\n",
      "Actual: 23.809411764705878  Predict: 20.946968385204674\n",
      "Actual: 34.25541666666667  Predict: 21.22926323954016\n",
      "Actual: 21.66904761904762  Predict: 27.45859524086118\n",
      "Actual: 13.125  Predict: 20.208759985677897\n",
      "Actual: 22.592916666666667  Predict: 15.767997992224991\n",
      "Actual: 26.147391304347824  Predict: 20.877303338237105\n",
      "Actual: 20.58315789473684  Predict: 22.89311094712466\n",
      "Actual: 25.022499999999997  Predict: 19.76765434090048\n",
      "Actual: 27.69625  Predict: 22.474394217133522\n",
      "Actual: 25.86521739130435  Predict: 23.7113111153245\n",
      "Actual: 20.472999999999995  Predict: 22.432899351231754\n",
      "Actual: 24.110416666666666  Predict: 20.08598902951926\n",
      "Actual: 26.95823529411765  Predict: 21.58504942469299\n",
      "Actual: 25.508333333333336  Predict: 23.239536986872555\n",
      "Actual: 25.917916666666667  Predict: 22.3072771769017\n",
      "Actual: 29.45  Predict: 22.63084253501147\n",
      "Actual: 27.371666666666663  Predict: 24.778753351792695\n",
      "Actual: 25.25260869565217  Predict: 23.459471297450364\n",
      "Actual: 25.032608695652176  Predict: 22.26391464788467\n",
      "Actual: 33.152499999999996  Predict: 22.334524441324174\n",
      "Actual: 23.82526315789474  Predict: 26.736464510113002\n",
      "Actual: 25.611666666666665  Predict: 21.633979772776364\n",
      "Actual: 23.425833333333333  Predict: 22.764231277257203\n",
      "Actual: 17.025454545454547  Predict: 21.20877594538033\n",
      "Actual: 9.60578947368421  Predict: 17.01851851195097\n",
      "Actual: 18.453333333333333  Predict: 12.729086954332889\n",
      "Actual: 10.493913043478258  Predict: 18.1899143923074\n",
      "Actual: 11.342631578947367  Predict: 13.291573722846806\n",
      "Actual: 13.606666666666667  Predict: 14.280534693505615\n",
      "Actual: 22.162500000000005  Predict: 15.93441526517272\n",
      "Actual: 25.425833333333337  Predict: 21.08213019464165\n",
      "Actual: 15.926666666666666  Predict: 22.690833329595627\n",
      "Actual: 13.733809523809525  Predict: 16.427723306789993\n",
      "Actual: 25.683333333333337  Predict: 14.92586869355291\n",
      "Actual: 39.76083333333333  Predict: 22.29611485786736\n",
      "Actual: 23.85818181818182  Predict: 30.66233846358955\n",
      "Actual: 21.564090909090908  Predict: 21.24886400010437\n",
      "Actual: 12.588636363636365  Predict: 19.866248761862515\n",
      "Actual: 16.0025  Predict: 14.830724598281085\n",
      "Actual: 28.229047619047616  Predict: 17.274349550157787\n",
      "Actual: 27.8625  Predict: 24.150490884110333\n",
      "Actual: 32.4775  Predict: 23.970394797995688\n",
      "Actual: 37.275416666666665  Predict: 26.612172742560507\n",
      "Actual: 19.855000000000004  Predict: 29.21471278294921\n",
      "Actual: 20.989166666666662  Predict: 19.244447923451663\n",
      "Actual: 23.06041666666667  Predict: 19.518721528537572\n",
      "Actual: 32.42318181818182  Predict: 21.445790884085\n",
      "Actual: 32.37590909090909  Predict: 26.568513085320593\n",
      "Actual: 25.614545454545453  Predict: 26.23752437271178\n",
      "Actual: 38.822916666666664  Predict: 21.689074621908368\n",
      "Actual: 39.04875  Predict: 29.9526240542531\n",
      "Actual: 40.623125  Predict: 30.192579955980182\n",
      "Actual: 37.01238095238095  Predict: 31.01440508849919\n",
      "Actual: 46.12649999999999  Predict: 28.889045697450637\n",
      "Actual: 55.85545454545454  Predict: 34.39705830998719\n",
      "Actual: 34.224347826086955  Predict: 49.15232700705528\n",
      "Actual: 25.689999999999998  Predict: 33.4242653593421\n",
      "Actual: 30.93428571428571  Predict: 27.01329463068396\n",
      "Actual: 20.225416666666664  Predict: 31.226200511306523\n",
      "Actual: 30.684736842105263  Predict: 23.63493460882455\n",
      "Actual: 21.493529411764705  Predict: 30.47640896216035\n",
      "Actual: 23.288749999999997  Predict: 24.50956003293395\n",
      "Actual: 26.141428571428573  Predict: 25.53542614802718\n",
      "Actual: 24.766363636363636  Predict: 27.81853273175657\n",
      "Actual: 36.806666666666665  Predict: 26.852071644179524\n",
      "Actual: 35.43590909090909  Predict: 35.31671503223479\n",
      "Actual: 30.49590909090909  Predict: 34.23949788361788\n",
      "Actual: 17.65791666666667  Predict: 30.74123146422207\n",
      "Actual: 25.328095238095237  Predict: 21.631332299672067\n",
      "Actual: 23.90666666666666  Predict: 27.18657495919615\n",
      "Actual: 30.730416666666667  Predict: 25.786102921143176\n",
      "Actual: 36.89  Predict: 30.717936611548065\n",
      "Actual: 53.89526315789474  Predict: 30.70664573907852\n",
      "Actual: 35.207368421052635  Predict: 42.70964117571711\n",
      "Actual: 42.0275  Predict: 29.53177891597152\n",
      "Actual: 30.93875  Predict: 34.15314878374338\n",
      "Actual: 28.13875  Predict: 27.157018584012985\n",
      "Actual: 21.71125  Predict: 25.071382204443218\n",
      "Actual: 24.537647058823527  Predict: 20.760205711983144\n",
      "Actual: 32.45782608695652  Predict: 22.955134341306984\n",
      "Actual: 18.422000000000004  Predict: 27.74530578441918\n",
      "Actual: 9.710434782608695  Predict: 19.498383404873312\n",
      "Actual: 9.206  Predict: 14.70609143646434\n",
      "Actual: 12.18388888888889  Predict: 14.425111829303205\n",
      "Actual: 7.841818181818183  Predict: 16.051610519271343\n",
      "Actual: 23.13818181818182  Predict: 13.667807787191123\n",
      "Actual: 29.47666666666667  Predict: 22.157308679819106\n",
      "Actual: 29.221666666666668  Predict: 25.880949888192117\n",
      "Actual: 14.458333333333334  Predict: 25.72241803444922\n",
      "Actual: 12.356315789473683  Predict: 17.299086384288966\n",
      "Actual: 27.03833333333333  Predict: 16.14581229360774\n",
      "Actual: 27.242499999999996  Predict: 24.390843361057343\n",
      "Actual: 22.93285714285714  Predict: 24.508631052449346\n",
      "Actual: 17.70111111111111  Predict: 22.040591862797736\n",
      "Actual: 22.795833333333334  Predict: 19.095989322848617\n",
      "Actual: 34.444583333333334  Predict: 21.962751545011997\n",
      "Actual: 35.106521739130436  Predict: 29.03864308744669\n",
      "Actual: 37.90083333333333  Predict: 29.47606434226036\n",
      "Actual: 41.520833333333336  Predict: 31.334682631865142\n",
      "Actual: 42.67166666666666  Predict: 33.79681806564331\n",
      "Actual: 37.449090909090906  Predict: 34.6095231808722\n",
      "Actual: 10.080416666666666  Predict: 31.032885251194237\n",
      "Actual: 43.784  Predict: 14.907312126457692\n",
      "Actual: 13.692727272727272  Predict: 35.398392548784614\n",
      "Actual: 15.952000000000002  Predict: 16.877990202978253\n",
      "Actual: 22.023750000000003  Predict: 18.124084118567406\n",
      "Actual: 27.874166666666667  Predict: 21.524869438260794\n",
      "Actual: 23.888571428571428  Predict: 24.887127535976468\n",
      "Actual: 35.3195  Predict: 22.58459604308009\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(inv_y)):\n",
    "    print(f\"Actual: {inv_y[i]}  Predict: {inv_yhat[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
